

::: {.content-visible when-format="pdf"}
```{r, echo = F, out.width="300px"}
#| fig-cap: "Luxembourg is about as big as the US State of Rhode Island."
knitr::include_graphics("images/lux_rhode_island.png")
```
:::


```{r, echo = F}
#https://ec.europa.eu/eurostat/databrowser/bookmark/21530d9a-c423-4ab7-998a-7170326136cd?lang=en
housing_lu_eu <- read.csv("datasets/prc_hpi_a__custom_4705395_page_linear.csv.gz")

withr::with_package("ggplot2",
  {
    ggplot(data = housing_lu_eu) +
      geom_line(aes(y = OBS_VALUE, x = TIME_PERIOD, group = geo, colour = geo),
                linewidth = 1.5) +
      labs(title = "House price and sales index (2010 = 100)",
           caption = "Source: Eurostat") +
      theme_minimal() +
      theme(legend.position = "bottom")
  }
  )

```



::: {.content-visible when-format="pdf"}
```{r, echo = F}
#| fig-cap: "An Excel file meant for human eyes."
knitr::include_graphics("images/obs_hab_xlsx_overview.png")
```
:::

```{r, warning = FALSE, message = FALSE}
library(dplyr)
library(purrr)
library(readxl)
library(stringr)
library(janitor)
```



```{r, warning = FALSE, message = FALSE}
# The url below points to an Excel file
# hosted on the book’s github repository
url <- "https://is.gd/1vvBAc"

raw_data <- tempfile(fileext = ".xlsx")

download.file(url, raw_data,
              method = "auto",
              mode = "wb")

sheets <- excel_sheets(raw_data)

read_clean <- function(..., sheet){
  read_excel(..., sheet = sheet) |>
    mutate(year = sheet)
}

raw_data <- map(
  sheets,
  ~read_clean(raw_data,
              skip = 10,
              sheet = .)
                   ) |>
  bind_rows() |>
  clean_names()

raw_data <- raw_data |>
  rename(
    locality = commune,
    n_offers = nombre_doffres,
    average_price_nominal_euros = prix_moyen_annonce_en_courant,
    average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant,
    average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant
  ) |>
  mutate(locality = str_trim(locality)) |>
  select(year, locality, n_offers, starts_with("average"))
```


```{r}
raw_data
```



```{r}
raw_data |>
  filter(grepl("Luxembourg", locality)) |>
  count(locality)

```

We can see that the city of Luxembourg is spelled in two different ways. It's the same with another commune, Pétange:

```{r}
raw_data |>
  filter(grepl("P.tange", locality)) |>
  count(locality)

```

So sometimes it is spelled correctly, with an "é", sometimes not. Let's write some code to correct both these issues:

```{r}
raw_data <- raw_data |>
  mutate(
    locality = ifelse(grepl("Luxembourg-Ville", locality),
                      "Luxembourg",
                      locality),
         locality = ifelse(grepl("P.tange", locality),
                           "Pétange",
                           locality)
         ) |>
  mutate(across(starts_with("average"),
         as.numeric))

```


```{r}
raw_data |>
  filter(is.na(average_price_nominal_euros))
```



::: {.content-visible when-format="pdf"}
```{r, echo = F}
#| fig-cap: "Always look at your data."
knitr::include_graphics("images/obs_hab_xlsx_missing.png")
```


```{r}
raw_data <- raw_data |>
  filter(!grepl("Source", locality))
```

Let's now only keep the communes in our data:

```{r}
commune_level_data <- raw_data |>
    filter(!grepl("nationale|offres", locality),
           !is.na(locality))
```

And let's create a dataset with the national data as well:

```{r}
country_level <- raw_data |>
  filter(grepl("nationale", locality)) |>
  select(-n_offers)

offers_country <- raw_data |>
  filter(grepl("Total d.offres", locality)) |>
  select(year, n_offers)

country_level_data <- full_join(country_level, offers_country) |>
  select(year, locality, n_offers, everything()) |>
  mutate(locality = "Grand-Duchy of Luxembourg")

```



```{r}
current_communes <- "https://is.gd/lux_communes" |>
  rvest::read_html() |>
  rvest::html_table() |>
  purrr::pluck(2) |>
  janitor::clean_names() |>
  dplyr::filter(name_2 != "Name") |>
  dplyr::rename(commune = name_2) |>
  dplyr::mutate(commune = stringr::str_remove(commune, " .$"))
```



```{r}
setdiff(unique(commune_level_data$locality),
        current_communes$commune)
```



```{r}
former_communes <- "https://is.gd/lux_former_communes" |>
  rvest::read_html() |>
  rvest::html_table() |>
  purrr::pluck(3) |>
  janitor::clean_names() |>
  dplyr::filter(year_dissolved > 2009)

head(former_communes)

```

As you can see, since 2010 many communes have merged to form new ones. We can now combine the list of current and former communes, as well as harmonise their names:

```{r}
communes <- unique(c(former_communes$name,
                     current_communes$commune))
# we need to rename some communes

# Different spelling of these communes between wikipedia and the data

communes[which(communes == "Clemency")] <- "Clémency"
communes[which(communes == "Redange")] <- "Redange-sur-Attert"
communes[which(communes == "Erpeldange-sur-Sûre")] <- "Erpeldange"
communes[which(communes == "Luxembourg City")] <- "Luxembourg"
communes[which(communes == "Käerjeng")] <- "Kaerjeng"
communes[which(communes == "Petange")] <- "Pétange"
```

Let's run our test again:

```{r}
library(ggplot2)
setdiff(unique(commune_level_data$locality),
      communes)

length(unique(raw_data$locality))
head(raw_data$locality)
average_prices <- aggregate(raw_data$average_price_m2_nominal_euros ~ raw_data$locality, data=raw_data, FUN=mean)

head(average_prices)

head(average_prices[order(average_prices$`raw_data$average_price_m2_nominal_euros`),])

result <- raw_data %>%
  group_by(year) %>%
  filter(!is.na(average_price_m2_nominal_euros)) %>%
  slice_min(order_by = average_price_m2_nominal_euros, n = 1)


raw_data %>%
  filter(!is.na(average_price_m2_nominal_euros)) %>%
  group_by(year) %>%
  summarise(avg_price = mean(average_price_m2_nominal_euros)) %>%
  
  ggplot(aes(x = factor(year), y = avg_price)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Average Prices by Year", x = "Year", y = "Average Price(Euro Per m2)")

ggplot(result, aes(x = year, y = average_price_nominal_euros)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Average House Prices by Year", x = "Year", y = "Average Price (In USD)")+
  theme_minimal()


# Finding minimum prices of each year and their locality


data_2010 <- raw_data[raw_data$year == 2010, ]

min_price_2010 <- min(data_2010$average_price_m2_nominal_euros[!is.na(data_2010$average_price_m2_nominal_euros)])

# inflation and house prices
raw_data <- raw_data %>%
  filter(year >= 2010 & year <= 2021) %>%
  group_by(year) %>%
  summarise(price_change = diff(average_price_nominal_euros[!is.na(average_price_nominal_euros)]))


inflation_data <- data.frame(
  year = 2010:2021,
  inflation_rate = c(2.27, 3.41, 2.66, 1.73, 0.63, 0.47, 0.29, 1.73, 1.53, 1.74, 0.82, 2.53))
merged_data <- merge(inflation_data, raw_data, by = "year"   
                     )

# I found the average prices of houses in each town whose names were corrupted in the data and after removing the "NA" data. I also observed how house prices changed each year. It is also possible to observe what I have mentioned graphically. You can clear all the data and see their ranking from cheap to expensive according to their average prices.

# I will try to get one more graphic in the future as development. From Luxembourg government sources, I found the annual inflations on the specified dates. I want to find the change in average house prices on a yearly and percentage basis and compare them under the same scale. In this way, we will be able to clearly see how house prices move against inflation.



```
